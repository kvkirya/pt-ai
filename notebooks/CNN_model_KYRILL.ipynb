{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205cefef",
   "metadata": {},
   "source": [
    "# Requirements üìã‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4368d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 14:07:38.599698: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 14:07:38.774964: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-01 14:07:38.775040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-01 14:07:38.781158: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-01 14:07:38.818233: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 14:07:38.819672: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 14:07:42.477047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "# import cv2\n",
    "\n",
    "# Needed for the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Needed for the CNN\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d476464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6f4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import convert_to_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee526c",
   "metadata": {},
   "source": [
    "# Hopefully fixing cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41e7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5831431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be41ad",
   "metadata": {},
   "source": [
    "# The Dataset location üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Data Load ‚è≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "validation_split = 0.2\n",
    "num_classes = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4772 files belonging to 4 classes.\n",
      "Using 3818 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 14:09:02.421058: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    directory='/home/kyrill/code/pt-ai/pt-ai/raw_data/processed_data_03',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4772 files belonging to 4 classes.\n",
      "Using 954 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = image_dataset_from_directory(\n",
    "    directory='/home/kyrill/code/pt-ai/pt-ai/raw_data/processed_data_03',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8cf4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4099ff1",
   "metadata": {},
   "source": [
    "## Preprocessing ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Function ü¶æüíªüß†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca18dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_CNN():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Preprocessing layers\n",
    "    model.add(layers.CenterCrop(height=350, width=450, input_shape=[256,256,1]))\n",
    "\n",
    "    # Build of the Model\n",
    "    model.add(layers.Conv2D(filters=8, kernel_size=(4,4), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "    model.add(layers.Conv2D(16,(3,3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compilation of the Model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc4999b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " center_crop (CenterCrop)    (None, 350, 450, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 350, 450, 8)       136       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 175, 225, 8)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 173, 223, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 86, 111, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 152736)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1527370   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 44        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1528718 (5.83 MB)\n",
      "Trainable params: 1528718 (5.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary of the CNN model\n",
    "tmp_first_CNN = initialize_CNN()\n",
    "tmp_first_CNN.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c196b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=1, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b122aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 195s 2s/step - loss: 1.3670 - accuracy: 0.3279 - val_loss: 1.3507 - val_accuracy: 0.3532\n"
     ]
    }
   ],
   "source": [
    "history = tmp_first_CNN.fit(train_dataset,\n",
    "                            epochs=1,\n",
    "                            validation_data=validation_dataset,\n",
    "                            batch_size=16,\n",
    "                            callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 9s 285ms/step - loss: 1.3507 - accuracy: 0.3532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.350656270980835, 0.3532494902610779]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_first_CNN.evaluate(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
